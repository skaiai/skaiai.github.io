<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Skaiai</title>
		<description>Welcome！</description>
		<link>http://localhost:4000/skaiai.github.io</link>
		<atom:link href="http://localhost:4000/skaiai.github.io/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Sequence-to-Sequence Models for ASR (1)</title>
				<description>&lt;!--last update: 2018-09-20 &lt;br/&gt;&lt;br/&gt;--&gt;

&lt;p&gt;last update: 2018-09-20&lt;/p&gt;

&lt;hr /&gt;
&lt;!-- &gt; End-to-end approach to speech recognition is appealing to us, as it turns separate models such as AM (acoustic), PM (pronunciation), LM (language) of conventional hybrid ASR system into one single neural network model.&lt;br/&gt;&lt;br/&gt;Seq-to-seq models have been used for this purpose and I'd like to review them.&lt;br/&gt; --&gt;

&lt;p&gt;End-to-end approach to speech recognition is appealing to us, as it turns separate models such as AM (acoustic), PM (pronunciation), LM (language) of conventional hybrid ASR system into one single neural network model.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Seq-to-seq models have been used for this purpose and I’d like to review them.&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;seq2seq-models&quot;&gt;Seq2Seq Models&lt;/h2&gt;
&lt;h4 id=&quot;1-connectionist-temporal-classification-ctc&quot;&gt;1. Connectionist temporal classification (&lt;strong&gt;CTC&lt;/strong&gt;)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.toronto.edu/~graves/icml_2006.pdf&quot;&gt;Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;when: 2006 by Alex Graves&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-recurrent-neural-netowrk-transducer-rnn-t&quot;&gt;2. Recurrent neural netowrk Transducer (&lt;strong&gt;RNN-T&lt;/strong&gt;)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1211.3711.pdf&quot;&gt;Sequence transduction with recurrent neural networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;when: Nov 2012 by Alex Graves&lt;/li&gt;
  &lt;li&gt;description: extension of CTC (it augments CTC w/ prediction network)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;3-attention-based-model&quot;&gt;3. Attention-based Model&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;LAS&lt;/strong&gt; model (non-streaming input)
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1508.01211.pdf&quot;&gt;Listen, Attend and Spell&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;when: Aug 2015 by CMU, Google Brain&lt;/li&gt;
      &lt;li&gt;description: encoder, decoder and attention btw them. non-streaming input&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nueral Transducer&lt;/strong&gt; (streaming input)
    &lt;ul&gt;
      &lt;li&gt;improved: &lt;a href=&quot;https://pdfs.semanticscholar.org/9409/ce44b3c6b1b55479f3ff0f87f4e7c52f227a.pdf&quot;&gt;Improving the performance of online neural transducer models&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;Dec 2017 by Google&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;org: &lt;a href=&quot;http://bengio.abracadoudou.com/cv/publications/pdf/jaitly_2016_nips.pdf&quot;&gt;An online sequence-to-sequence model using partial conditioning&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;when: 2016 by Google Brain / DeepMind, OpenAI&lt;/li&gt;
          &lt;li&gt;description: streaming input&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;4-rnn-t-w-attention&quot;&gt;4. &lt;strong&gt;RNN-T w/ Attention&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://pdfs.semanticscholar.org/6cc6/8e8adf34b580f3f37d1bd267ee701974edde.pdf&quot;&gt;A comparison of sequence-to-sequence models for speech recognition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;2017 by Google, NVIDIA&lt;/li&gt;
  &lt;li&gt;description: modification to the RNN transducer replacing the prediction network w/ attention-based decoder entwork used in LAS&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;5-transformer&quot;&gt;5. &lt;strong&gt;Transformer&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf&quot;&gt;Attention is all you need&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;2017 by Google Brain/Research, University of Toronto&lt;/li&gt;
  &lt;li&gt;description: attention operations are introduced in encoder and decoder nets both instead of rnn or cnn&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;Next post will be discussing Transformer model and how to apply it to ASR task.&lt;/p&gt;
</description>
				<pubDate>Thu, 20 Sep 2018 00:00:00 +0900</pubDate>
				<link>http://localhost:4000/skaiai.github.io/speech-recognition/2018/09/20/seq2seq_for_asr.html</link>
				<guid isPermaLink="true">http://localhost:4000/skaiai.github.io/speech-recognition/2018/09/20/seq2seq_for_asr.html</guid>
			</item>
		
			<item>
				<title>[Paper] State-of-the-art speech recognition with sequence-to-sequence models</title>
				<description>&lt;p&gt;last update: 2018-09-20  &lt;br /&gt;
paper: &lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/ko//pubs/archive/46687.pdf&quot;&gt;State-of-the-art speech recognition with sequence-to-sequence models (Feb 2018)&lt;/a&gt;
&lt;!--[example pic](/skaiai.github.io/assets/images/post_180920/header.png= 250x)--&gt;
&lt;img name=&quot;header&quot; img=&quot;&quot; src=&quot;/skaiai.github.io/assets/images/post_180920/header.png&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;
&lt;p&gt;improved version of LAS model&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;structural side
    &lt;ul&gt;
      &lt;li&gt;words instead of graphemes&lt;/li&gt;
      &lt;li&gt;multi-head attention instead of a single-head one&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;optimization side
    &lt;ul&gt;
      &lt;li&gt;synchronous training&lt;/li&gt;
      &lt;li&gt;scheduled sampling&lt;/li&gt;
      &lt;li&gt;label smoothing&lt;/li&gt;
      &lt;li&gt;minimum word error rate optimization&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
				<pubDate>Thu, 20 Sep 2018 00:00:00 +0900</pubDate>
				<link>http://localhost:4000/skaiai.github.io/speech-recognition/2018/09/20/paper-sota_sr_seq2seq.html</link>
				<guid isPermaLink="true">http://localhost:4000/skaiai.github.io/speech-recognition/2018/09/20/paper-sota_sr_seq2seq.html</guid>
			</item>
		
			<item>
				<title>[Paper] Listen, Attend and Spell</title>
				<description>&lt;p&gt;last update: 2018-09-20  &lt;br /&gt;
paper: &lt;a href=&quot;https://arxiv.org/pdf/1508.01211.pdf&quot;&gt;Listen, Attend and Spell (Aug 2015)&lt;/a&gt;
&lt;img name=&quot;header&quot; img=&quot;&quot; src=&quot;/skaiai.github.io/assets/images/post_180920/header_las.png&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro&lt;/h1&gt;

</description>
				<pubDate>Thu, 20 Sep 2018 00:00:00 +0900</pubDate>
				<link>http://localhost:4000/skaiai.github.io/speech-recognition/2018/09/20/paper-LAS.html</link>
				<guid isPermaLink="true">http://localhost:4000/skaiai.github.io/speech-recognition/2018/09/20/paper-LAS.html</guid>
			</item>
		
			<item>
				<title>ReadMe</title>
				<description>&lt;h1 id=&quot;license&quot;&gt;License&lt;/h1&gt;
&lt;p&gt;The content of this theme is distributed and licensed under a
&lt;img src=&quot;/skaiai.github.io/assets/images/cc_by_88x31.png&quot; alt=&quot;License Badge&quot; /&gt;
&lt;a href=&quot;https://creativecommons.org/licenses/by/4.0/legalcode&quot;&gt;Creative Commons Attribution 4.0 License&lt;/a&gt;
    This license lets others distribute, remix, tweak, and build upon your work,
    even commercially, as long as they credit you for the original creation. This
    is the most accommodating of licenses offered. Recommended for maximum
    dissemination and use of licensed materials.&lt;/p&gt;

&lt;h1 id=&quot;thanks&quot;&gt;Thanks&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;[Bootstrap][bootstrap-url]&lt;/li&gt;
  &lt;li&gt;[Jekyll Clean Theme][Jekyll-Clean-Theme-url]&lt;/li&gt;
  &lt;li&gt;[Theme Maker][xixia-url]
[bootstrap-url]: http://getbootstrap.com/
[Jekyll-Clean-Theme-url]: https://github.com/scotte/jekyll-clean
[xixia-url]: http://xixia.info/&lt;/li&gt;
&lt;/ol&gt;
</description>
				<pubDate>Sun, 02 Sep 2018 00:00:00 +0900</pubDate>
				<link>http://localhost:4000/skaiai.github.io/other/2018/09/02/README.html</link>
				<guid isPermaLink="true">http://localhost:4000/skaiai.github.io/other/2018/09/02/README.html</guid>
			</item>
		
	</channel>
</rss>
